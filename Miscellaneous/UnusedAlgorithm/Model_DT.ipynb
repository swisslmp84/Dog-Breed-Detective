{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "642900ed-5007-40d7-92c3-be2134e48b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#computer vision library\n",
    "import cv2\n",
    "#glob\n",
    "from glob import glob\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82000eee-eff9-4ea9-a263-33612509c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_training_and_test():\n",
    "    npzfile = np.load('training_data.npz')\n",
    "    train_data = npzfile['arr_0']\n",
    "    \n",
    "    npzfile = np.load('training_labels.npz')\n",
    "    train_labels = npzfile['arr_0']\n",
    "    \n",
    "    npzfile = np.load('test_data.npz')\n",
    "    test_data = npzfile['arr_0']\n",
    "\n",
    "    npzfile = np.load('test_labels.npz')\n",
    "    test_labels = npzfile['arr_0']\n",
    "    \n",
    "    return (train_data, train_labels), (test_data, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3240ead7-a72b-4c08-aea6-398b1e39e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_DT, y_train_DT), (x_test_DT, y_test_DT) = load_data_training_and_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eb5fd51-6ea4-4b75-ae17-1d38cbb3968a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17756, 40000)\n",
      "(17756,)\n",
      "(4370, 40000)\n",
      "(4370,)\n"
     ]
    }
   ],
   "source": [
    "# Change our image type to float32 data type\n",
    "x_train_DT = x_train_DT.astype('float32')\n",
    "x_test_DT = x_test_DT.astype('float32')\n",
    "\n",
    "# Normalize our data by changing the range from (0 to 255) to (0 to 1)\n",
    "x_train_DT /= 255\n",
    "x_test_DT /= 255\n",
    "\n",
    "print(x_train_DT.shape)\n",
    "print(y_train_DT.shape)\n",
    "print(x_test_DT.shape)\n",
    "print(y_test_DT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed0a4249-0cf2-44ae-9a61-1a52a170abc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3496, 40000)\n",
      "(3496,)\n",
      "(874, 40000)\n",
      "(874,)\n"
     ]
    }
   ],
   "source": [
    "## as the data set is too huge for the DT to complete. we will reduce the images in the dataset by using the split test function against the test set of 4320 images\n",
    "X_train_DT_R, X_test_DT_R, y_train_DT_R, y_test_DT_R = train_test_split(x_test_DT, y_test_DT, test_size=0.2)\n",
    "\n",
    "print(X_train_DT_R.shape)\n",
    "print(y_train_DT_R.shape)\n",
    "print(X_test_DT_R.shape)\n",
    "print(y_test_DT_R.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcc4c66f-ffba-4b12-8584-94b5e0fb9cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc=DecisionTreeClassifier()\n",
    "\n",
    "dtc.fit(X_train_DT_R,y_train_DT_R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17adb113-5c15-4d76-b0e2-c96ad8128b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 46,  46,  24,  42,  94,  19, 119,  41,  72,   2,   4,  59, 117,\n",
       "        39,  64, 106,  40,  83,   0,  65,  90,  74,   7,  42,  21,  45,\n",
       "         2,  83,  83, 109,  54,  12,  99,  48, 119,  82,  86,   9,   0,\n",
       "        57,  26,  26,  80,  54,  75,  82, 102,  55,  87,  12,  34, 114,\n",
       "        24,  63,  39,  85,  82,  81,   6,  83, 103,  57,   0, 117,  85,\n",
       "        29,  41, 118,  55,  26,  53,  58,  22,  25,  12,   7, 110,  35,\n",
       "       108,  27,   2, 116,  81, 115,  67,   1,  32,   5,  25, 113,  39,\n",
       "        27,   1,  59,  61, 100,  25,  88,  41,  13,  39, 102,  66,  53,\n",
       "       109,  16,  34,   6, 101,  19,  67, 108,  42,  73,  42,  34,  78,\n",
       "        24,  80,  33,  23,  69,  36,  92,  91, 109,  69,  88,  88,  59,\n",
       "       112, 100,  96,  11,  52,   0,  12,  58,  92,  12,  96,  34,   6,\n",
       "        30,  92,  52,  42,   6,  34,   4,  71,  84,  85,   2,  82, 107,\n",
       "        81,  21,  82,  11,  58, 114,  96,  90,  25,  22,  50,  35,  87,\n",
       "        90,  41,   7,   4, 105, 118,  88,   7,  12,  82,  98, 111,  73,\n",
       "        89,  43,  98,  46,  56,  53,  73,  85, 101, 105,  76,  73, 117,\n",
       "        81,  62,  81,  29,  72, 110,  77,  71,  63,  26,  71,  61,  66,\n",
       "        28,  64,  88,  12, 101, 103, 108,   3,  40,  39,   9, 115,  83,\n",
       "        14,  29,  60, 118,  13,  52, 115,  64,  50,  90,  35,  60,  21,\n",
       "        71,  36, 107,  21,  40,  89,  92,  27,  46,   0,  34, 110,  69,\n",
       "        28,  20,   9, 108,  40,  24,  25,  81, 118,  65,  24,  87,  57,\n",
       "       116,  61, 118, 103, 109,  30,  96,  96,  65,  79,  41,  42,  95,\n",
       "        40,  23, 102, 119,  38,  89,  39,  62, 115,  22,  10,  89,  71,\n",
       "        95,  63,  96,  22,  51,   4,  26,  28, 108, 106,  78,  85,  73,\n",
       "        50,  63,  41,  98,   9,  15,  54,  23,  10, 104,  72,  35, 106,\n",
       "         9, 114,  34,  13,   7,  56, 113,   7,  82, 101,  26, 117,  64,\n",
       "        51,   5, 102,  37, 113,  53,  58,  67,  59,  20,   8,  50,  22,\n",
       "         6, 101,   6, 101,  47,  35,  25,  91,  77,  21,  99,  35, 100,\n",
       "        37,  56,  47,  58,  86,   5, 108, 106,   9,   3,  38,  79,  63,\n",
       "        95,  16,   9,  41,  92, 100,  38,  42,  13,   8,  44,  11,   6,\n",
       "        70,  26,   7,   9,   3,  79,   9, 113,  19,  98,  28,  64,  13,\n",
       "       107,   7,  41,  43,  87,  28,  52,  59, 104,  30,   7,  56,  88,\n",
       "         1,  89,  95,  48, 104,  94,  66,  16, 107, 106,  15,  59, 104,\n",
       "        53,  83,  31,  38,   1,  23,   4,   5,  25,  34,   0,  74, 100,\n",
       "       102,  16,  38,  20,  37,  19,  15, 100, 106,   8,  63,   1, 109,\n",
       "        36, 115,  75, 115,  18,  95, 100,  25,  84,   9,  73,  27,  46,\n",
       "        10,  33,  57,  24,  47,  69,  74, 119, 100,  78,  34,  96,  82,\n",
       "        34,  42,  18,  60,  42,  97,  60,  67, 116,  26,  28,  70, 106,\n",
       "        31,  86,  28,  16,  20,   5, 105,  35,   2,  64,  40,   6,  34,\n",
       "       103,  26, 108,  56,  86,  92,  99,  45, 119,  42,  47,  62, 109,\n",
       "        18,  38,  22,   6,  30, 101,  40, 100, 107,   0,  14,  47,  16,\n",
       "        73,  53,  42,  63,  36,  39,  45,  45,  99, 101, 101,  40,  23,\n",
       "        38,  79,  39,  28,  67, 110,  77,  28, 101,   1,   7,  18,  18,\n",
       "        47,  77,  49,  99,  73,  55,  71,  13, 108,  23,  66,  47,  16,\n",
       "       100,  83,  16,   9,  11,  33,   0,  19,  21,  22, 104,  99,  90,\n",
       "        57,  88,  69,  19,  88,   9,  98,  20,  22,   6,  60, 116,  11,\n",
       "        41,  88,  42,  64,  27,  25,  93,   8,  61,  64,  31,  98,  36,\n",
       "        51, 116,   8,  39,  61,  76,  73,   3,  30,  31,  19, 112,  62,\n",
       "        41,   8,  41, 118,  19, 119, 108,  96, 112,  76,  49,  87,  78,\n",
       "        24,  48,  83,  50,   9,  63,  33,  34,  23,  99,  36,  33,  94,\n",
       "       114,  77,  40,  56,  96,  25,   6,  39, 107,  82,  83, 103,  74,\n",
       "        60, 107,   9,  40, 100,  72,  38,  54,  77,  39,  55, 117, 119,\n",
       "        99,  43, 105,  71,  90, 117,   4, 100,  97,  40,  46,  37,  62,\n",
       "        82,  26,  82,  70,  16,  79,  11,  59,  82,  91,  28,  42,  67,\n",
       "       113,   1,  47,  24, 103,  67,  98,   8,  53,  82,  25,  47, 101,\n",
       "        64,  73,  33,   6, 104, 119,  88,  64,  19,  96,  38,  47,  82,\n",
       "        62,  89,  26, 109,  39, 114,  85,  69,  93,  41,  16,  10,   8,\n",
       "        82,  29,  42, 108,  79,  46, 101, 111,  69,  26,  84,  41,  46,\n",
       "        70,  26,  93, 114,  63,  51,   4,  28,  27,  38, 108,   9,  84,\n",
       "         8,  35, 118,  92,  84,  31,  54,  55,  81,  19,  56,  47,  20,\n",
       "         6, 117,  95,  52,  28,  39,  14,  67,   7,  30,  20,  81,  89,\n",
       "        67,   1,  40,  77, 110, 110, 118,  34,  19, 119, 104,   2,   7,\n",
       "        27, 100, 102,  59,  31, 119,  23,  32, 108,  39,  91,  67,  76,\n",
       "        22,  57,  95,  80,  71,  33,  18,  49,  43,  73,  92,  27,  86,\n",
       "        36,   7, 108,  53,  33,  78, 109,  88,  76, 119,   4,  57,  45,\n",
       "        63, 102,  36,  28,  52,  67, 109, 105, 102,   6,  28,  25,  31,\n",
       "        37,  35,  72,  59,  54,  98, 108,  79,  48,  47,  76,  97,  27,\n",
       "        63,  35, 101,  66, 101,  30,  67,  60, 118,  47,  23,  78,  95,\n",
       "        72,  52,  42], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred_dtc=dtc.predict(X_test_DT_R)\n",
    "\n",
    "y_pred_dtc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8e0092e-794b-4c70-a541-db4f8dca29d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00         8\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00        14\n",
      "           7       0.00      0.00      0.00        13\n",
      "           8       0.00      0.00      0.00         9\n",
      "           9       0.00      0.00      0.00        15\n",
      "          10       0.00      0.00      0.00         4\n",
      "          11       0.00      0.00      0.00         6\n",
      "          12       0.00      0.00      0.00         7\n",
      "          13       0.00      0.00      0.00         6\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.00      0.00      0.00        10\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         6\n",
      "          19       0.00      0.00      0.00        11\n",
      "          20       0.00      0.00      0.00         7\n",
      "          21       0.00      0.00      0.00         6\n",
      "          22       0.17      0.11      0.13         9\n",
      "          23       0.00      0.00      0.00         9\n",
      "          24       0.00      0.00      0.00         8\n",
      "          25       0.00      0.00      0.00        12\n",
      "          26       0.00      0.00      0.00        13\n",
      "          27       0.17      0.11      0.13         9\n",
      "          28       0.00      0.00      0.00        14\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00         7\n",
      "          31       0.00      0.00      0.00         7\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         8\n",
      "          34       0.00      0.00      0.00        13\n",
      "          35       0.09      0.10      0.10        10\n",
      "          36       0.00      0.00      0.00         8\n",
      "          37       0.00      0.00      0.00         5\n",
      "          38       0.00      0.00      0.00        10\n",
      "          39       0.20      0.14      0.17        14\n",
      "          40       0.00      0.00      0.00        12\n",
      "          41       0.00      0.00      0.00        13\n",
      "          42       0.08      0.07      0.07        15\n",
      "          43       0.00      0.00      0.00         4\n",
      "          44       0.00      0.00      0.00         1\n",
      "          45       0.00      0.00      0.00         5\n",
      "          46       0.00      0.00      0.00         8\n",
      "          47       0.00      0.00      0.00        13\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.11      0.33      0.17         3\n",
      "          50       0.00      0.00      0.00         5\n",
      "          51       0.00      0.00      0.00         4\n",
      "          52       0.10      0.14      0.12         7\n",
      "          53       0.00      0.00      0.00         8\n",
      "          54       0.00      0.00      0.00         6\n",
      "          55       0.00      0.00      0.00         5\n",
      "          56       0.00      0.00      0.00         7\n",
      "          57       0.10      0.14      0.12         7\n",
      "          58       0.12      0.20      0.15         5\n",
      "          59       0.17      0.11      0.13         9\n",
      "          60       0.00      0.00      0.00         7\n",
      "          61       0.00      0.00      0.00         5\n",
      "          62       0.00      0.00      0.00         6\n",
      "          63       0.11      0.09      0.10        11\n",
      "          64       0.14      0.10      0.12        10\n",
      "          65       0.00      0.00      0.00         3\n",
      "          66       0.00      0.00      0.00         5\n",
      "          67       0.00      0.00      0.00        12\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         7\n",
      "          70       0.00      0.00      0.00         4\n",
      "          71       0.00      0.00      0.00         8\n",
      "          72       0.10      0.17      0.12         6\n",
      "          73       0.00      0.00      0.00        11\n",
      "          74       0.00      0.00      0.00         4\n",
      "          75       0.00      0.00      0.00         2\n",
      "          76       0.00      0.00      0.00         6\n",
      "          77       0.00      0.00      0.00         7\n",
      "          78       0.00      0.00      0.00         6\n",
      "          79       0.00      0.00      0.00         7\n",
      "          80       0.00      0.00      0.00         3\n",
      "          81       0.00      0.00      0.00         8\n",
      "          82       0.12      0.07      0.09        15\n",
      "          83       0.00      0.00      0.00         9\n",
      "          84       0.00      0.00      0.00         5\n",
      "          85       0.25      0.17      0.20         6\n",
      "          86       0.00      0.00      0.00         5\n",
      "          87       0.00      0.00      0.00         5\n",
      "          88       0.00      0.00      0.00        11\n",
      "          89       0.00      0.00      0.00         7\n",
      "          90       0.00      0.00      0.00         6\n",
      "          91       0.00      0.00      0.00         4\n",
      "          92       0.00      0.00      0.00         8\n",
      "          93       0.00      0.00      0.00         3\n",
      "          94       0.20      0.33      0.25         3\n",
      "          95       0.17      0.12      0.14         8\n",
      "          96       0.00      0.00      0.00        10\n",
      "          97       0.00      0.00      0.00         3\n",
      "          98       0.00      0.00      0.00         8\n",
      "          99       0.00      0.00      0.00         8\n",
      "         100       0.00      0.00      0.00        13\n",
      "         101       0.00      0.00      0.00        14\n",
      "         102       0.00      0.00      0.00         8\n",
      "         103       0.00      0.00      0.00         6\n",
      "         104       0.00      0.00      0.00         7\n",
      "         105       0.00      0.00      0.00         5\n",
      "         106       0.00      0.00      0.00         7\n",
      "         107       0.00      0.00      0.00         7\n",
      "         108       0.29      0.14      0.19        14\n",
      "         109       0.00      0.00      0.00         9\n",
      "         110       0.00      0.00      0.00         6\n",
      "         111       0.00      0.00      0.00         2\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.00      0.00      0.00         5\n",
      "         114       0.00      0.00      0.00         6\n",
      "         115       0.00      0.00      0.00         6\n",
      "         116       0.00      0.00      0.00         5\n",
      "         117       0.00      0.00      0.00         7\n",
      "         118       0.00      0.00      0.00         9\n",
      "         119       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.02       874\n",
      "   macro avg       0.02      0.02      0.02       874\n",
      "weighted avg       0.03      0.02      0.02       874\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy_score(y_pred_dtc,y_test_DT_R)\n",
    "print(classification_report(y_pred_dtc,y_test_DT_R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa03086-9031-4072-aee4-7d22f7078006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf5b054-5622-4aff-97c6-459f3e1a9c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8012cb0d-7f85-429d-b8c9-8805177bd266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
